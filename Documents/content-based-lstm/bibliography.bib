@misc{top-artist-site,
title = {{The Top 1% of Artists Earn 77% of Recorded Music Income, Study Finds…
}},
url = {https://www.digitalmusicnews.com/2014/03/05/toponepercent/},
urldate = {2018-04-28},
year = {2014}
}
@article{Hochreiter1997,
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
doi = {10.1162/neco.1997.9.8.1735},
issn = {0899-7667},
journal = {Neural Computation},
month = {nov},
number = {8},
pages = {1735--1780},
title = {{Long Short-Term Memory}},
url = {http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735},
volume = {9},
year = {1997}
}
@misc{pydub-site,
title = {{jiaaro/pydub @ GitHub}},
url = {http://pydub.com/},
urldate = {2018-04-28},
year = {2018}
}
@misc{librosa-site,
title = {{LibROSA — librosa 0.6.0 documentation}},
url = {http://librosa.github.io/librosa/},
urldate = {2018-04-28},
year = {2018}
}
@misc{spotify_recent,
title = {{Get Current User's Recently Played Tracks | Spotify for Developers}},
url = {https://beta.developer.spotify.com/documentation/web-api/reference/player/get-recently-played/},
urldate = {2018-04-27},
year = {2018}
}
@misc{spotify_top,
title = {{Get a User's Top Artists and Tracks | Spotify for Developers}},
url = {https://beta.developer.spotify.com/documentation/web-api/reference/personalization/get-users-top-artists-and-tracks/},
urldate = {2018-04-27},
year = {2018}
}
@misc{spotify_permissions,
title = {{Authorization Scopes | Spotify for Developers}},
url = {https://beta.developer.spotify.com/documentation/general/guides/scopes/},
urldate = {2018-04-27},
year = {2018}
}
@incollection{NIPS2013_5004,
author = {van den Oord, Aaron and Dieleman, Sander and Schrauwen, Benjamin},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {Burges, C J C and Bottou, L and Welling, M and Ghahramani, Z and Weinberger, K Q},
pages = {2643--2651},
publisher = {Curran Associates, Inc.},
title = {{Deep content-based music recommendation}},
url = {http://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf},
year = {2013}
}
@inproceedings{Wang:2014:ICH:2647868.2654940,
address = {New York, NY, USA},
author = {Wang, Xinxi and Wang, Ye},
booktitle = {Proceedings of the 22Nd ACM International Conference on Multimedia},
doi = {10.1145/2647868.2654940},
isbn = {978-1-4503-3063-3},
keywords = {deep learning,feature learning,music recommendation,probabilistic graphical model},
pages = {627--636},
publisher = {ACM},
series = {MM '14},
title = {{Improving Content-based and Hybrid Music Recommendation Using Deep Learning}},
url = {http://doi.acm.org/10.1145/2647868.2654940},
year = {2014}
}
@misc{map_site,
title = {{Million Song Dataset Echo Nest Mapping Archive}},
url = {https://labs.acousticbrainz.org/million-song-dataset-echonest-archive/},
urldate = {2018-04-25},
year = {2018}
}
@misc{etp_site,
title = {{The Echo Nest Taste Profile Subset}},
url = {https://labrosa.ee.columbia.edu/millionsong/tasteprofile},
urldate = {2018-02-01},
year = {2018}
}
@misc{msd_site,
title = {{Million Song Dataset}},
url = {https://labrosa.ee.columbia.edu/millionsong/},
urldate = {2018-02-01},
year = {2018}
}
@article{Wang2014,
abstract = {Collaborative filtering (CF) is a successful approach commonly used by many recommender systems. Conventional CF-based methods use the ratings given to items by users as the sole source of information for learning to make recommendation. However, the ratings are often very sparse in many applications, causing CF-based methods to degrade significantly in their recommendation performance. To address this sparsity problem, auxiliary information such as item content information may be utilized. Collaborative topic regression (CTR) is an appealing recent method taking this approach which tightly couples the two components that learn from two different sources of information. Nevertheless, the latent representation learned by CTR may not be very effective when the auxiliary information is very sparse. To address this problem, we generalize recent advances in deep learning from i.i.d. input to non-i.i.d. (CF-based) input and propose in this paper a hierarchical Bayesian model called collaborative deep learning (CDL), which jointly performs deep representation learning for the content information and collaborative filtering for the ratings (feedback) matrix. Extensive experiments on three real-world datasets from different domains show that CDL can significantly advance the state of the art.},
archivePrefix = {arXiv},
arxivId = {1409.2944},
author = {Wang, Hao and Wang, Naiyan and Yeung, Dit-Yan},
doi = {10.1145/2783258.2783273},
eprint = {1409.2944},
isbn = {9781450336642},
issn = {9781450336642},
keywords = {deep learning,recommender systems,text,topic model},
title = {{Collaborative Deep Learning for Recommender Systems}},
url = {http://arxiv.org/abs/1409.2944},
year = {2014}
}
@article{Sundermeyer2015,
abstract = {Language models have traditionally been estimated based on relative$\backslash$nfrequencies, using count statistics that can be extracted from huge$\backslash$namounts of text data. More recently, it has been found that neural$\backslash$nnetworks are particularly powerful at estimating probability$\backslash$ndistributions over word sequences, giving substantial improvements over$\backslash$nstate-of-the-art count models. However, the performance of neural$\backslash$nnetwork language models strongly depends on their architectural$\backslash$nstructure. This paper compares count models to feedforward, recurrent,$\backslash$nand long short-term memory (LSTM) neural network variants on two$\backslash$nlarge-vocabulary speech recognition tasks. We evaluate the models in$\backslash$nterms of perplexity and word error rate, experimentally validating the$\backslash$nstrong correlation of the two quantities, which we find to hold$\backslash$nregardless of the underlying type of the language model. Furthermore,$\backslash$nneural networks incur an increased computational complexity compared to$\backslash$ncount models, and they differently model context dependences, often$\backslash$nexceeding the number of words that are taken into account by count based$\backslash$napproaches. These differences require efficient search methods for$\backslash$nneural networks, and we analyze the potential improvements that can be$\backslash$nobtained when applying advanced algorithms to the rescoring of word$\backslash$nlattices on large-scale setups.},
author = {Sundermeyer, Martin and Ney, Hermann and Schluter, Ralf},
doi = {10.1109/TASLP.2015.2400218},
isbn = {2329-9290 VO  - 23},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Feedforward neural network,Kneser-Ney smoothing,language modeling,long short-term memory (LSTM),recurrent neural network (RNN)},
number = {3},
pages = {517--529},
title = {{From feedforward to recurrent LSTM neural networks for language modeling}},
volume = {23},
year = {2015}
}
@article{Srivastava2015,
abstract = {We use multilayer Long Short Term Memory (LSTM) networks to learn representations of video sequences. Our model uses an encoder LSTM to map an input sequence into a fixed length representation. This representation is decoded using single or multiple decoder LSTMs to perform different tasks, such as reconstructing the input sequence, or predicting the future sequence. We experiment with two kinds of input sequences - patches of image pixels and high-level representations ("percepts") of video frames extracted using a pretrained convolutional net. We explore different design choices such as whether the decoder LSTMs should condition on the generated output. We analyze the outputs of the model qualitatively to see how well the model can extrapolate the learned video representation into the future and into the past. We try to visualize and interpret the learned features. We stress test the model by running it on longer time scales and on out-of-domain data. We further evaluate the representations by finetuning them for a supervised learning problem - human action recognition on the UCF-101 and HMDB-51 datasets. We show that the representations help improve classification accuracy, especially when there are only a few training examples. Even models pretrained on unrelated datasets (300 hours of YouTube videos) can help action recognition performance.},
archivePrefix = {arXiv},
arxivId = {1502.04681},
author = {Srivastava, Nitish and Mansimov, Elman and Salakhutdinov, Ruslan},
doi = {citeulike-article-id:13519737},
eprint = {1502.04681},
title = {{Unsupervised Learning of Video Representations using LSTMs}},
url = {http://arxiv.org/abs/1502.04681},
year = {2015}
}